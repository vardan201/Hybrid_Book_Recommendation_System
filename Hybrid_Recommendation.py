# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lACojq_qi8OIieCG64GjLBV3pw0eyrCG
"""

!pip uninstall -y numpy
!pip install numpy==1.24.4
!pip install scikit-surprise

import numpy as np
import pandas as pd
from surprise import SVD
from surprise import Dataset, Reader
from sklearn.metrics.pairwise import cosine_similarity
import pickle

# --------------------------------------------
# üîß Load Data and Model
# --------------------------------------------
books = pd.read_csv("/content/books_cleaned.csv")
ratings = pd.read_csv("/content/ratings.csv")

# Load trained SVD model
with open('/content/svd_model.pkl', 'rb') as f:
    svd_model = pickle.load(f)

# Load TF-IDF matrix
with open('/content/tfidf_matrix.pkl', 'rb') as f:
    tfidf_matrix = pickle.load(f)

# Compute cosine similarity manually
cosine_sim_matrix = cosine_similarity(tfidf_matrix)

# --------------------------------------------
# üßπ Preprocess
# --------------------------------------------
books['title'] = books['title'].fillna('').str.lower()
books['book_id'] = books['book_id'].astype(int)
ratings['book_id'] = ratings['book_id'].astype(int)
ratings['user_id'] = ratings['user_id'].astype(int)

# Book ID to title and reverse mapping
book_id_to_title = books.set_index('book_id')['title'].to_dict()
title_to_book_id = books.set_index('title')['book_id'].to_dict()

# Filter to books that are rated
rated_book_ids = set(ratings['book_id'].unique())

# --------------------------------------------
# üß† Hybrid Recommendation Function
# --------------------------------------------
def get_hybrid_recommendations(book_title, top_n=10):
    book_title = book_title.lower()
    if book_title not in title_to_book_id:
        return f"‚ùå Book title '{book_title}' not found in dataset."

    book_id = title_to_book_id[book_title]
    book_idx = books.index[books['book_id'] == book_id][0]

    # --- Content-based part ---
    sim_scores = list(enumerate(cosine_sim_matrix[book_idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:top_n + 20]  # Get more in case some are unrated

    content_recommendations = []
    for idx, sim_score in sim_scores:
        candidate_id = books.iloc[idx]['book_id']
        candidate_title = books.iloc[idx]['title'].title()

        if candidate_id in rated_book_ids:
            # --- Hybrid: average of collaborative + content ---
            candidate_users = ratings[ratings['book_id'] == book_id]['user_id'].unique()
            if len(candidate_users) == 0:
                continue
            user_id = candidate_users[0]
            try:
                pred_rating = svd_model.predict(user_id, candidate_id).est
                hybrid_score = (sim_score * 5 + pred_rating) / 2  # weighted average
            except:
                hybrid_score = sim_score * 5  # fallback
        else:
            hybrid_score = sim_score * 5  # scale similarity to 5

        content_recommendations.append((candidate_title, round(hybrid_score, 3)))

    # Sort and get top N
    content_recommendations = sorted(content_recommendations, key=lambda x: x[1], reverse=True)
    return content_recommendations[:top_n]



from sklearn.feature_extraction.text import TfidfVectorizer
import pickle

# Create TF-IDF matrix
tfidf = TfidfVectorizer(stop_words='english')
tfidf_matrix = tfidf.fit_transform(books['content'])

# Save the TF-IDF matrix
with open('/content/tfidf_matrix.pkl', 'wb') as f:
    pickle.dump(tfidf_matrix, f)

print("TF-IDF matrix regenerated and saved.")

book_input = "bagombo snuff box"  # Change as needed
recommendations = get_hybrid_recommendations(book_input, top_n=5)

print(f"\nüìò Hybrid Recommendations for '{book_input.title()}':")
if isinstance(recommendations, list):
    for i, (title, score) in enumerate(recommendations, 1):
        print(f"{i}. {title} (Hybrid Score: {score})")
else:
    print(recommendations)















